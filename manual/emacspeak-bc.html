<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.6.0" />
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <title>Beautiful Code</title>
  <link rel="stylesheet" href="docbook.css" type="text/css" />
  <meta name="generator" content=
  "DocBook XSL Stylesheets V1.68.1" />
  <style type="text/css">
  /*<![CDATA[*/
  table.c8 {border-collapse: collapse;}
  td.c7 {border-right: 0.5pt solid ;}
  td.c6 {border-bottom: 0.5pt solid ;}
  td.c5 {border-right: 0.5pt solid ; border-bottom: 0.5pt solid ;}
  th.c4 {border-bottom: 0.5pt solid ;}
  th.c3 {border-right: 0.5pt solid ; border-bottom: 0.5pt solid ;}
  h2.c2 {clear: both}
  /*]]>*/
  </style>
</head>
<body>
  <div class="book" lang="en" xml:lang="en">
    <div class="titlepage">
      <div>
        <h1 class="title"><a id="I_book_tt2" name=
        "I_book_tt2"></a>Beautiful Code</h1>
      </div>
      <hr />
    </div>
    <div class="chapter" lang="en" xml:lang="en">
      <div class="titlepage">
        <h2 class="title"><a id=
        "emacspeak_the_complete_audio_desktop" name=
        "emacspeak_the_complete_audio_desktop"></a>Chapter&nbsp;31.&nbsp;Emacspeak:
        The Complete Audio Desktop</h2>
      </div>
      <p><span class="emphasis"><em>T. V. Raman</em></span> <a id=
      "idx-CHP-31-2630" class="indexterm" name=
      "idx-CHP-31-2630"></a></p>
      <p><span class="emphasis"><em>A desktop is a workspace that
      one uses to organize the tools of one's trade</em></span> .
      Graphical desktops provide rich visual interaction for
      performing day-to-day computing tasks; the goal of the
      <span class="emphasis"><em>audio desktop</em></span> is to
      enable similar efficiencies in an eyes-free environment.
      Thus, the primary goal of an audio desktop is to use the
      expressiveness of auditory output (both verbal and nonverbal)
      to enable the end user to perform a full range of computing
      tasks:</p>
      <div class="itemizedlist">
        <ul type="disc">
          <li>
            <p>Communication through the full range of electronic
            messaging services</p>
          </li>
          <li>
            <p>Ready access to local documents on the client and
            global documents on the Web</p>
          </li>
          <li>
            <p>Ability to develop software effectively in an
            eyes-free environment</p>
          </li>
        </ul>
      </div>
      <p>The <a id="idx-CHP-31-2631" class="indexterm" name=
      "idx-CHP-31-2631"></a>Emacspeak audio desktop was motivated
      by the following insight: to provide effective auditory
      renderings of information, one needs to start from the actual
      information being presented, rather than a visual
      presentation of that information. This had earlier led me to
      develop <a id="idx-CHP-31-2632" class="indexterm" name=
      "idx-CHP-31-2632"></a>AsTeR, Audio System For Technical
      Readings ( <a href=
      "http://emacspeak.sf.net/raman/aster/aster-toplevel.html"
      target=
      "_top">http://emacspeak.sf.net/raman/aster/aster-toplevel.html</a>).
      The primary motivation then was to apply the lessons learned
      in the context of aural documents to user interfaces—after
      all, the document <span class="emphasis"><em>is</em></span>
      the interface.</p>
      <p>The primary goal was not to merely carry the visual
      interface over to the auditory modality, but rather to create
      an eyes-free user interface that is both pleasant and
      productive to use.</p>
      <p>Contrast this with the traditional screen-reader approach
      where GUI widgets such as sliders and tree controls are
      directly translated to <a id="idx-CHP-31-2633" class=
      "indexterm" name="idx-CHP-31-2633"></a>spoken output. Though
      such direct translation can give the appearance of providing
      full eyes-free access, the resulting auditory user interface
      can be inefficient to use.</p>
      <p>These prerequisites meant that the environment selected
      for the audio desktop needed:</p>
      <div class="itemizedlist">
        <ul type="disc">
          <li>
            <p>A core set of speech and nonspeech audio output
            services</p>
          </li>
          <li>
            <p>A rich suite of pre-existing applications to
            speech-enable</p>
          </li>
          <li>
            <p>Access to application context to produce contextual
            feedback</p>
          </li>
        </ul>
      </div>
      <div class="sect1" lang="en" xml:lang="en">
        <div class="titlepage">
          <h2 class="title c2"><a id="producing_spoken_output"
          name="producing_spoken_output"></a>31.1.&nbsp;Producing
          Spoken Output</h2>
        </div>
        <p>I started implementing <a id="idx-CHP-31-2634" class=
        "indexterm" name="idx-CHP-31-2634"></a>Emacspeak in October
        1994. The target environments were a Linux laptop and my
        office workstation. To produce speech output, I used a
        <a id="idx-CHP-31-2635" class="indexterm" name=
        "idx-CHP-31-2635"></a>DECTalk Express (a <a id=
        "idx-CHP-31-2636" class="indexterm" name=
        "idx-CHP-31-2636"></a>hardware speech synthesizer) on the
        laptop and a software version of the DECTalk on the office
        workstation. <a id="idx-CHP-31-2637" class="indexterm"
        name="idx-CHP-31-2637"></a></p>
        <p>The most natural way to design the system to leverage
        both speech options was to first implement a speech server
        that abstracted away the distinction between the two output
        solutions. The speech server abstraction has withstood the
        test of time well; I was able to add support for the IBM
        ViaVoice engine later, in 1999. Moreover, the simplicity of
        the client/server API has enabled open source programmers
        to implement <a id="idx-CHP-31-2638" class="indexterm"
        name="idx-CHP-31-2638"></a>speech servers for other speech
        engines.</p>
        <p><a id="idx-CHP-31-2639" class="indexterm" name=
        "idx-CHP-31-2639"></a>Emacspeak speech servers are
        implemented in the <a id="idx-CHP-31-2640" class=
        "indexterm" name="idx-CHP-31-2640"></a>TCL language. The
        speech server for the DECTalk Express communicated with the
        hardware synthesizer over a serial line. As an example, the
        command to speak a string of text was a <code class=
        "literal">proc</code> that took a string argument and wrote
        it to the serial device. A simplified version of this looks
        like:</p><a id="I_programlisting31_tt687" name=
        "I_programlisting31_tt687"></a>
        <pre class="programlisting">
        proc tts_say {text} {puts -nonewline $tts(write) "$text"}

</pre>
        <p>The speech server for the software DECTalk implemented
        an equivalent, simplified <code class=
        "literal">tts_say</code> version that looks like:</p><a id=
        "I_programlisting31_tt688" name=
        "I_programlisting31_tt688"></a>
        <pre class="programlisting">
        proc say {text} {_say "$text"}

</pre>
        <p>where <code class="literal">_say</code> calls the
        underlying C implementation provided by the DECTalk
        software.</p>
        <p>The net result of this design was to create separate
        speech servers for each available engine, where each speech
        server was a simple script that invoked TCL's default
        readeval-print loop after loading in the relevant
        definitions. The client/server API therefore came down to
        the client (Emacspeak) launching the appropriate speech
        server, caching this connection, and invoking server
        commands by issuing appropriate procedure calls over this
        connection.</p>
        <p>Notice that so far I have said nothing explicit about
        how this client/server connection was opened; this
        late-binding proved beneficial later when it came to making
        Emacspeak network-aware. Thus, the initial implementation
        worked by the <a id="idx-CHP-31-2641" class="indexterm"
        name="idx-CHP-31-2641"></a>Emacspeak client communicating
        to the speech server using <code class=
        "literal">stdio</code> . Later, making this client/server
        communication go over the network required the addition of
        a few lines of code that opened a server socket and
        connected <code class="literal">stdin/stdout</code> to the
        resulting connection.</p>
        <p>Thus, designing a clean client/server abstraction, and
        relying on the power of Unix I/O, has made it trivial to
        later run Emacspeak on a remote machine and have it connect
        back to a speech server running on a local client. This
        enables me to run Emacspeak inside <span class=
        "emphasis"><em>screen</em></span> on my work machine, and
        access this running session from anywhere in the world.
        Upon connecting, I have the remote Emacspeak session
        connect to a speech server on my laptop, the audio
        equivalent of setting up X to use a remote display.</p>
      </div>
      <div class="sect1" lang="en" xml:lang="en">
        <div class="titlepage">
          <h2 class="title c2"><a id="speech-enabling_emacs" name=
          "speech-enabling_emacs"></a>31.2.&nbsp;Speech-Enabling
          Emacs</h2>
        </div>
        <p>The simplicity of the speech server abstraction
        described above meant that version 0 of the speech server
        was running within an hour after I started <a id=
        "idx-CHP-31-2642" class="indexterm" name=
        "idx-CHP-31-2642"></a>implementing the system. This meant
        that I could then move on to the more interesting part of
        the project: producing good quality spoken output. Version
        0 of the speech server was by no means perfect; it was
        improved as I built the Emacspeak speech client. <a id=
        "idx-CHP-31-2643" class="indexterm" name=
        "idx-CHP-31-2643"></a></p>
        <div class="sect2" lang="en" xml:lang="en">
          <div class="titlepage">
            <h3 class="title"><a id=
            "a_simple_first-cut_implementation" name=
            "a_simple_first-cut_implementation"></a>A Simple
            First-Cut Implementation</h3>
          </div>
          <p>A friend of mine had pointed me at the marvels of
          Emacs Lisp <span class="emphasis"><em>advice</em></span>
          a few weeks earlier. So when I sat down to speech-enable
          Emacs, <span class="emphasis"><em>advice</em></span> was
          the natural choice. The first task was to have Emacs
          automatically speak the line under the cursor whenever
          the user pressed the up/down arrow keys. <a id=
          "idx-CHP-31-2644" class="indexterm" name=
          "idx-CHP-31-2644"></a> <a id="idx-CHP-31-2645" class=
          "indexterm" name="idx-CHP-31-2645"></a> <a id=
          "idx-CHP-31-2646" class="indexterm" name=
          "idx-CHP-31-2646"></a></p>
          <p>In Emacs, all user actions invoke appropriate Emacs
          Lisp functions. In standard editing modes, pressing the
          down arrow invokes function <code class=
          "literal">next-line</code> , while pressing the up arrow
          invokes <code class="literal">previous-line</code> . To
          speech-enable these commands, version 0 of Emacspeak
          implemented the following rather simple advice
          fragment:</p><a id="I_programlisting31_tt689" name=
          "I_programlisting31_tt689"></a>
          <pre class="programlisting">
        (defadvice next-line (after emacspeak)
          "Speak line after moving."
          (when (interactive-p) (
<a id="idx-CHP-31-2647" class="indexterm" name=
"idx-CHP-31-2647"></a>emacspeak-speak-line)))

</pre>
          <p>The <code class="literal">emacspeak-speak-line</code>
          function implemented the necessary logic to grab the text
          of the line under the cursor and send it to the speech
          server. With the previous definition in place, Emacspeak
          0.0 was up and running; it provided the scaffolding for
          building the actual system.</p>
        </div>
        <div class="sect2" lang="en" xml:lang="en">
          <div class="titlepage">
            <h3 class="title"><a id=
            "iterating_on_the_first-cut_implementation" name=
            "iterating_on_the_first-cut_implementation"></a>Iterating
            on the First-Cut Implementation</h3>
          </div>
          <p>The next iteration returned to the speech server to
          enhance it with a well-defined <a id="idx-CHP-31-2648"
          class="indexterm" name="idx-CHP-31-2648"></a>eventing
          loop. Rather than simply executing each speech command as
          it was received, the speech server queued client requests
          and provided a <code class="literal">launch</code>
          command that caused the server to execute queued
          requests. <a id="idx-CHP-31-2649" class="indexterm" name=
          "idx-CHP-31-2649"></a></p>
          <p>The server used the <code class=
          "literal">select</code> system call to check for newly
          arrived commands after sending each clause to the speech
          engine. This enabled immediate silencing of speech; with
          the somewhat naïve implementation described in version 0
          of the speech server, the command to stop speech would
          not take immediate effect since the speech server would
          first process previously issued <code class=
          "literal">speak</code> commands to completion. With the
          speech queue in place, the client application could now
          queue up arbitrary amounts of <a id="idx-CHP-31-2650"
          class="indexterm" name="idx-CHP-31-2650"></a>text and
          still get a high degree of responsiveness when issuing
          higher-priority commands such as requests to stop
          speech.</p>
          <p>Implementing an event queue inside the speech server
          also gave the client application finer control over how
          text was split into chunks before synthesis. This turns
          out to be crucial for producing good <a id=
          "idx-CHP-31-2651" class="indexterm" name=
          "idx-CHP-31-2651"></a>intonation structure. The rules by
          which text should be split up into clauses varies
          depending on the nature of the text being spoken. As an
          example, newline characters in programming languages such
          as Python are statement delimiters and determine clause
          boundaries, but newlines do not constitute clause
          delimiters in English text.</p>
          <p>As an example, a clause boundary is inserted after
          each line when speaking the following Python
          code:</p><a id="I_programlisting31_tt690" name=
          "I_programlisting31_tt690"></a>
          <pre class="programlisting">
        i=1
        j=2

</pre>
          <p>See the section "Augmenting <a id="idx-CHP-31-2652"
          class="indexterm" name="idx-CHP-31-2652"></a>Emacs to
          create aural display lists," later in this chapter, for
          details on how Python code is distinguished and its
          semantics are transferred to the speech layer.</p>
          <p>With the speech server now capable of smart text
          handling, the <a id="idx-CHP-31-2653" class="indexterm"
          name="idx-CHP-31-2653"></a>Emacspeak client could become
          more sophisticated with respect to its handling of text.
          The <code class="literal">emacspeak-speak-line</code>
          function turned into a library of speech-generation
          functions that implemented the following steps:</p>
          <div class="itemizedlist">
            <ul type="disc">
              <li>
                <p>Parse text to split it into a sequence of
                clauses.</p>
              </li>
              <li>
                <p>Preprocess text—e.g., handle repeated strings of
                punctuation marks.</p>
              </li>
              <li>
                <p>Carry out a number of other functions that got
                added over time.</p>
              </li>
              <li>
                <p>Queue each clause to the speech server, and
                issue the <code class="literal">launch</code>
                command.</p>
              </li>
            </ul>
          </div>
          <p>From here on, the rest of Emacspeak was implemented
          using Emacspeak as the development environment. This has
          been significant in how the code base has evolved. New
          features are tested immediately because badly implemented
          features can render the entire system unusable. Lisp's
          incremental code development fits naturally with the
          former; to cover the latter, the Emacspeak code base has
          evolved to be "bushy"—i.e., most parts of the
          higher-level system are mutually independent and depend
          on a small core that is carefully maintained.</p>
        </div>
        <div class="sect2" lang="en" xml:lang="en">
          <div class="titlepage">
            <h3 class="title"><a id="a_brief_advice_tutorial" name=
            "a_brief_advice_tutorial"></a>A Brief advice
            Tutorial</h3>
          </div>
          <p>Lisp <span class="emphasis"><em>advice</em></span> is
          key to the <a id="idx-CHP-31-2654" class="indexterm"
          name="idx-CHP-31-2654"></a>Emacspeak implementation, and
          this chapter would not be complete without a brief
          overview. The <span class=
          "emphasis"><em>advice</em></span> facility allows one to
          modify existing functions <span class=
          "emphasis"><em>without changing the original
          implementation</em></span> . What's more, once a function
          <code class="literal">f</code> has been modified by
          <span class="emphasis"><em>advice</em></span>
          <code class="literal">m</code> , all calls to function
          <code class="literal">f</code> are affected by
          <span class="emphasis"><em>advice</em></span> . <a id=
          "idx-CHP-31-2655" class="indexterm" name=
          "idx-CHP-31-2655"></a> <a id="idx-CHP-31-2656" class=
          "indexterm" name="idx-CHP-31-2656"></a></p>
          <p><span class="emphasis"><em>advice</em></span> comes in
          three flavors:</p>
          <div class="variablelist">
            <dl>
              <dt><span class="term"><code class=
              "literal">before</code></span></dt>
              <dd>
                <p>The advice body is run <span class=
                "emphasis"><em>before</em></span> the original
                function is invoked. <a id="idx-CHP-31-2657" class=
                "indexterm" name="idx-CHP-31-2657"></a></p>
              </dd>
              <dt><span class="term"><code class=
              "literal">after</code></span></dt>
              <dd>
                <p>The advice body is run <span class=
                "emphasis"><em>after</em></span> the original
                function has completed. <a id="idx-CHP-31-2658"
                class="indexterm" name="idx-CHP-31-2658"></a></p>
              </dd>
              <dt><span class="term"><code class=
              "literal">around</code></span></dt>
              <dd>
                <p>The advice body is run <span class=
                "emphasis"><em>instead of</em></span> the original
                function. The <code class="literal">around</code>
                advice can call the original function if desired.
                <a id="idx-CHP-31-2659" class="indexterm" name=
                "idx-CHP-31-2659"></a></p>
              </dd>
            </dl>
          </div>
          <p>All <span class="emphasis"><em>advice</em></span>
          forms get access to the arguments of the <span class=
          "emphasis"><em>adviced</em></span> function; in addition,
          <code class="literal">around</code> and after get access
          to the return value computed by the original function.
          The Lisp implementation achieves this magic by: <a id=
          "idx-CHP-31-2660" class="indexterm" name=
          "idx-CHP-31-2660"></a></p>
          <div class="orderedlist">
            <ol type="1">
              <li>
                <p>Caching the original implementation of the
                function</p>
              </li>
              <li>
                <p>Evaluating the advice form to generate a new
                function definition</p>
              </li>
              <li>
                <p>Storing this definition as the <span class=
                "emphasis"><em>adviced</em></span> function</p>
              </li>
            </ol>
          </div>
          <p>Thus, when the <span class=
          "emphasis"><em>advice</em></span> fragment shown in the
          earlier section "A Simple First-Cut Implementation" is
          evaluated, <a id="idx-CHP-31-2661" class="indexterm"
          name="idx-CHP-31-2661"></a>Emacs' original <code class=
          "literal">next-line</code> function is replaced by a
          modified version that speaks the current line
          <span class="emphasis"><em>after</em></span> the original
          <code class="literal">next-line</code> function has
          completed its work.</p>
        </div>
        <div class="sect2" lang="en" xml:lang="en">
          <div class="titlepage">
            <h3 class="title"><a id=
            "generating_rich_auditory_output" name=
            "generating_rich_auditory_output"></a>Generating Rich
            Auditory Output</h3>
          </div>
          <p>At this point in its evolution, here is what the
          overall design looked like: <a id="idx-CHP-31-2662"
          class="indexterm" name="idx-CHP-31-2662"></a></p>
          <div class="orderedlist">
            <ol type="1">
              <li>
                <p>Emacs' interactive commands are speech-enabled
                or <span class="emphasis"><em>adviced</em></span>
                to produce auditory output.</p>
              </li>
              <li>
                <p><span class="emphasis"><em>advice</em></span>
                definitions are collected into modules, one each
                for every Emacs application being
                speech-enabled.</p>
              </li>
              <li>
                <p>The <span class=
                "emphasis"><em>advice</em></span> forms forward
                text to core speech functions.</p>
              </li>
              <li>
                <p>These functions extract the text to be spoken
                and forward it to the <code class=
                "literal">tts-speak</code> function. <a id=
                "idx-CHP-31-2663" class="indexterm" name=
                "idx-CHP-31-2663"></a></p>
              </li>
              <li>
                <p>The <code class="literal">tts-speak</code>
                function produces auditory output by preprocessing
                its <code class="literal">text</code> argument and
                sending it to the speech server.</p>
              </li>
              <li>
                <p>The speech server handles queued requests to
                produce perceptible output.</p>
              </li>
            </ol>
          </div>
          <p>Text is preprocessed by placing the text in a special
          scratch buffer. Buffers acquire specialized behavior via
          buffer-specific <span class="emphasis"><em>syntax
          tables</em></span> that define the <span class=
          "emphasis"><em>grammar</em></span> of buffer contents and
          buffer-local variables that affect behavior. When text is
          handed off to the <a id="idx-CHP-31-2664" class=
          "indexterm" name="idx-CHP-31-2664"></a>Emacspeak core,
          all of these buffer-specific settings are propagated to
          the special scratch buffer where the text is
          preprocessed. This automatically ensures that text is
          meaningfully parsed into clauses based on its underlying
          grammar.</p>
          <div class="sect3" lang="en" xml:lang="en">
            <div class="titlepage">
              <h4 class="title"><a id=
              "audio_formatting_using_voice-lock" name=
              "audio_formatting_using_voice-lock"></a>Audio
              formatting using voice-lock</h4>
            </div>
            <p><a id="idx-CHP-31-2665" class="indexterm" name=
            "idx-CHP-31-2665"></a>Emacs uses <code class=
            "literal">font-lock</code> to syntactically color text.
            For creating the visual presentation, Emacs adds a text
            property called <code class="literal">face</code> to
            text strings; the value of this <code class=
            "literal">face</code> property specifies the font,
            color, and style to be used to display that text. Text
            strings with <code class="literal">face</code>
            properties can be thought of as a conceptual
            <span class="emphasis"><em>visual display
            list</em></span> . <a id="idx-CHP-31-2666" class=
            "indexterm" name="idx-CHP-31-2666"></a></p>
            <p>Emacspeak augments these visual display lists with
            <code class="literal">personality</code> text
            properties whose values specify the auditory properties
            to use when rendering a given piece of text; this is
            called <code class="literal">voice-lock</code> in
            Emacspeak. The value of the <code class=
            "literal">personality</code> property is an Aural CSS
            (ACSS) setting that encodes various voice
            properties—e.g., the pitch of the speaking voice.
            Notice that such ACSS settings are not specific to any
            given TTS engine. Emacspeak implements ACSS-to-TTS
            <a id="idx-CHP-31-2667" class="indexterm" name=
            "idx-CHP-31-2667"></a>mappings in engine-specific
            modules that take care of mapping high-level aural
            properties—e.g., mapping <code class=
            "literal">pitch</code> or <code class=
            "literal">pitch-range</code> to engine-specific control
            codes. <a id="idx-CHP-31-2668" class="indexterm" name=
            "idx-CHP-31-2668"></a></p>
            <p>The next few sections describe how Emacspeak
            augments Emacs to create aural display lists and to
            process these aural display lists to produce
            engine-specific output.</p>
          </div>
          <div class="sect3" lang="en" xml:lang="en">
            <div class="titlepage">
              <h4 class="title"><a id=
              "augmenting_emacs_to_create_aural_display_lists"
              name="augmenting_emacs_to_create_aural_display_lists">
              </a>Augmenting Emacs to create aural display
              lists</h4>
            </div>
            <p>Emacs modules that implement <code class=
            "literal">font-lock</code> call the Emacs built-in
            function <code class="literal">put-text-property</code>
            to attach the relevant <code class=
            "literal">face</code> property. Emacspeak defines an
            advice fragment that <span class=
            "emphasis"><em>advices</em></span> the <code class=
            "literal">put-text-property</code> function to add in
            the corresponding <code class=
            "literal">personality</code> property when it is asked
            to add a face property. Note that the value of both
            display properties ( <code class="literal">face</code>
            and <code class="literal">personality</code> ) can be
            lists; values of these properties are thus designed to
            <span class="emphasis"><em>cascade</em></span> to
            create the final (visual or auditory) presentation.
            This also means that different parts of an application
            can progressively add display property values. <a id=
            "idx-CHP-31-2669" class="indexterm" name=
            "idx-CHP-31-2669"></a> <a id="idx-CHP-31-2670" class=
            "indexterm" name="idx-CHP-31-2670"></a></p>
            <p>The <code class="literal">put-text-property</code>
            function has the following signature:</p><a id=
            "I_programlisting31_tt691" name=
            "I_programlisting31_tt691"></a>
            <pre class="programlisting">
        (put-text-property START END PROPERTY VALUE &amp;optional OBJECT)

</pre>
            <p>The <span class="emphasis"><em>advice</em></span>
            implementation is:</p><a id="I_programlisting31_tt692"
            name="I_programlisting31_tt692"></a>
            <pre class="programlisting">
        (defadvice put-text-property (after emacspeak-personality pre act)
          "Used by emacspeak to augment font lock."
          (let ((start (ad-get-arg 0)) ;; Bind arguments
                (end (ad-get-arg 1 ))
                (prop (ad-get-arg 2)) ;; name of property being added
                (value (ad-get-arg 3 ))
                (object (ad-get-arg 4))
                (voice nil))                   ;; voice it maps to
            (when (and (eq prop 'face)      ;; avoid infinite recursion
                       (not (= start end))  ;; non-nil text range
                       
<a id="idx-CHP-31-2671" class="indexterm" name=
"idx-CHP-31-2671"></a>emacspeak-personality-voiceify-faces)
              (condition-case nil ;; safely look up face mapping
                  (progn
                    (cond
                     ((symbolp value)
                      (setq voice (voice-setup-get-voice-for-face value)))
                     ((ems-plain-cons-p value)) ;;pass on plain cons
                     ( (listp value)
                       (setq voice
                             (delq nil
                                   (mapcar   #'voice-setup-get-voice-for-face value))))
                     (t (message "Got %s" value)))
                    (when voice ;; voice holds list of personalities
                      (funcall 
<a id="idx-CHP-31-2672" class="indexterm" name=
"idx-CHP-31-2672"></a>emacspeak-personality-voiceify-faces start end voice object)))
                (error nil)))))

</pre>
            <p>Here is a brief explanation of this <span class=
            "emphasis"><em>advice</em></span> definition:</p>
            <div class="variablelist">
              <dl>
                <dt><span class="term emphasis"><em>Bind
                arguments</em></span></dt>
                <dd>
                  <p>First, the function uses the <span class=
                  "emphasis"><em>advice</em></span> built-in
                  <code class="literal">ad-get-arg</code> to
                  locally bind a set of lexical variables to the
                  arguments being passed to the <span class=
                  "emphasis"><em>adviced</em></span> function.</p>
                </dd>
                <dt><span class="term emphasis"><em>Personality
                setter</em></span></dt>
                <dd>
                  <p>The mapping of faces to personalities is
                  controlled by user customizable variable
                  <code class=
                  "literal">emacspeak-personality-voiceify-faces</code>
                  . If non-nil, this variable specifies a function
                  with the following signature: <a id=
                  "idx-CHP-31-2673" class="indexterm" name=
                  "idx-CHP-31-2673"></a></p><a id=
                  "I_programlisting31_tt693" name=
                  "I_programlisting31_tt693"></a>
                  <pre class="programlisting">
        (
<a id="idx-CHP-31-2674" class="indexterm" name=
"idx-CHP-31-2674"></a>emacspeak-personality-put START END PERSONALITY OBJECT)

</pre>
                  <p>Emacspeak provides different implementations
                  of this function that either append or prepend
                  the new personality value to any existing
                  personality properties.</p>
                </dd>
                <dt><span class=
                "term emphasis"><em>Guard</em></span></dt>
                <dd>
                  <p>Along with checking for a non-nil <code class=
                  "literal">emacspeak-personality-voiceify-faces</code>
                  , the function performs additional checks to
                  determine whether this advice definition should
                  do anything. The function continues to act
                  if:</p>
                  <div class="itemizedlist">
                    <ul type="disc">
                      <li>
                        <p>The text range is non-nil.</p>
                      </li>
                      <li>
                        <p>The property being added is a
                        <code class="literal">face</code> .</p>
                      </li>
                    </ul>
                  </div>
                  <p>The first of these checks is required to avoid
                  edge cases where <code class=
                  "literal">put-text-property</code> is called with
                  a zero-length text range. The second ensures that
                  we attempt to add the <code class=
                  "literal">personality</code> property only when
                  the property being added is <code class=
                  "literal">face</code> . Notice that failure to
                  include this second test would cause infinite
                  recursion because the eventual <code class=
                  "literal">put-text-property</code> call that adds
                  the <code class="literal">personality</code>
                  property also triggers the advice definition.</p>
                </dd>
                <dt><span class="term emphasis"><em>Get
                mapping</em></span></dt>
                <dd>
                  <p>Next, the function <span class=
                  "emphasis"><em>safely</em></span> looks up the
                  voice mapping of the face (or faces) being
                  applied. If applying a single <code class=
                  "literal">face</code> , the function looks up the
                  corresponding personality mapping; if applying a
                  list of faces, it creates a corresponding list of
                  personalities.</p>
                </dd>
                <dt><span class="term emphasis"><em>Apply
                personality</em></span></dt>
                <dd>
                  <p>Finally, the function checks that it found a
                  valid voice mapping and, if so, calls
                  <code class="literal">emacspeak-personality-voiceify-faces</code>
                  with the set of personalities saved in the
                  <code class="literal">voice</code> variable.
                  <a id="idx-CHP-31-2675" class="indexterm" name=
                  "idx-CHP-31-2675"></a></p>
                </dd>
              </dl>
            </div>
          </div>
          <div class="sect3" lang="en" xml:lang="en">
            <div class="titlepage">
              <h4 class="title"><a id=
              "audio-formatted_output_from_aural_display_lists"
              name=
              "audio-formatted_output_from_aural_display_lists"></a>Audio-formatted
              output from aural display lists</h4>
            </div>
            <p>With the <span class=
            "emphasis"><em>advice</em></span> definitions from the
            previous section in place, text fragments that are
            visually styled acquire a corresponding <code class=
            "literal">personality</code> property that holds an
            ACSS setting for audio formatting the content. The
            result is to turn text in <a id="idx-CHP-31-2676"
            class="indexterm" name="idx-CHP-31-2676"></a>Emacs into
            <a id="idx-CHP-31-2677" class="indexterm" name=
            "idx-CHP-31-2677"></a>rich aural display lists. This
            section describes how the output layer of <a id=
            "idx-CHP-31-2678" class="indexterm" name=
            "idx-CHP-31-2678"></a>Emacspeak is enhanced to convert
            these aural display lists into perceptible spoken
            output. <a id="idx-CHP-31-2679" class="indexterm" name=
            "idx-CHP-31-2679"></a></p>
            <p>The Emacspeak <code class="literal">tts-speak</code>
            module handles <a id="idx-CHP-31-2680" class=
            "indexterm" name="idx-CHP-31-2680"></a>text
            preprocessing before finally sending it to the speech
            server. As described earlier, this preprocessing
            comprises a number of steps, including: <a id=
            "idx-CHP-31-2681" class="indexterm" name=
            "idx-CHP-31-2681"></a></p>
            <div class="orderedlist">
              <ol type="1">
                <li>
                  <p>Applying <a id="idx-CHP-31-2682" class=
                  "indexterm" name=
                  "idx-CHP-31-2682"></a>pronunciation rules</p>
                </li>
                <li>
                  <p>Processing repeated strings of <a id=
                  "idx-CHP-31-2683" class="indexterm" name=
                  "idx-CHP-31-2683"></a>punctuation characters</p>
                </li>
                <li>
                  <p><a id="idx-CHP-31-2684" class="indexterm"
                  name="idx-CHP-31-2684"></a>Splitting text into
                  appropriate clauses based on context</p>
                </li>
                <li>
                  <p><a id="idx-CHP-31-2685" class="indexterm"
                  name="idx-CHP-31-2685"></a>Converting the
                  <code class="literal">personality</code> property
                  into <a id="idx-CHP-31-2686" class="indexterm"
                  name="idx-CHP-31-2686"></a>audio formatting
                  codes</p>
                </li>
              </ol>
            </div>
            <p>This section describes the <code class=
            "literal">tts-format-text-and-speak</code> function,
            which handles the conversion of aural display lists
            into audio-formatted output. First, here is the code
            for the function <code class=
            "literal">tts-format-text-and-speak</code> : <a id=
            "idx-CHP-31-2687" class="indexterm" name=
            "idx-CHP-31-2687"></a> <a id="I_indexterm31_tt694"
            class="indexterm" name=
            "I_indexterm31_tt694"></a></p><a id=
            "I_programlisting31_tt695" name=
            "I_programlisting31_tt695"></a>
            <pre class="programlisting">
        (defsubst tts-format-text-and-speak (start end )
          "Format and speak text between start and end."
          (when (and emacspeak-use-auditory-icons
                     (get-text-property start 'auditory-icon)) ;;queue icon
            (emacspeak-queue-auditory-icon (get-text-property start 'auditory-icon)))
          (tts-interp-queue (format "%s\n" tts-voice-reset-code))
          (cond
           (voice-lock-mode ;; audio format only if voice-lock-mode is on
            (let ((last nil) ;; initialize
                  (personality (get-text-property start 'personality )))
              (while (and (
        &lt; start end ) ;; chunk at personality changes
                              (setq last
                                    (next-single-property-change start 'personality
                                                                 (current-buffer) end)))
                   (if personality ;; audio format chunk
                       (tts-speak-using-voice personality (buffer-substring start last ))
                     (tts-interp-queue (buffer-substring start last)))
                   (setq start last ;; prepare for next chunk
                         personality (get-text-property last 'personality)))))
              ;; no voice-lock just send the text
              (t (tts-interp-queue (buffer-substring start end )))))

</pre>
            <p>The <code class=
            "literal">tts-format-text-and-speak</code> function is
            called one clause at a time, with arguments
            <code class="literal">start</code> and <code class=
            "literal">end</code> set to the start and end of the
            clause. If <code class="literal">voice-lock-mode</code>
            is turned on, this function further splits the clause
            into chunks at each point in the text where there is a
            change in value of the <code class=
            "literal">personality</code> property. Once such a
            transition point has been determined, <code class=
            "literal">tts-format-text-and-speak</code> calls the
            function <code class=
            "literal">tts-speak-using-voice</code> , passing the
            personality to use and the text to be spoken. This
            function, described next, looks up the appropriate
            device-specific codes before dispatching the
            audio-formatted output to the speech server: <a id=
            "idx-CHP-31-2688" class="indexterm" name=
            "idx-CHP-31-2688"></a></p><a id=
            "I_programlisting31_tt696" name=
            "I_programlisting31_tt696"></a>
            <pre class="programlisting">
        (defsubst tts-speak-using-voice (voice text)
          "Use voice VOICE to speak text TEXT."
          (unless (or (eq '
<a id="idx-CHP-31-2689" class="indexterm" name=
"idx-CHP-31-2689"></a>inaudible voice ) ;; not spoken if voice inaudible
                      (and (listp voice) (member 'inaudible voice)))
            (tts-interp-queue
             (format
              "%s%s %s \n"
              (cond
               ((symbolp voice)
                (tts-get-voice-command
                 (if (boundp voice ) (symbol-value voice ) voice)))
               ((listp voice)
                (mapconcat #'(lambda (v)
                               (tts-get-voice-command
                                (if (boundp v ) (symbol-value v ) v)))
                           voice
                           " "))
               (t      ""))
              text tts-voice-reset-code))))

</pre>
            <p>The <code class=
            "literal">tts-speak-using-voice</code> function returns
            immediately if the specified voice is <code class=
            "literal">inaudible</code> . Here, <code class=
            "literal">inaudible</code> is a special personality
            that <a id="idx-CHP-31-2690" class="indexterm" name=
            "idx-CHP-31-2690"></a>Emacspeak uses to prevent pieces
            of text from being spoken. The <code class=
            "literal">inaudible</code> personality can be used to
            advantage when selectively hiding portions of text to
            produce more succinct output.</p>
            <p>If the specified voice (or list of voices) is not
            <code class="literal">inaudible</code> , the function
            looks up the speech codes for the voice and queues the
            result of wrapping the text to be spoken between
            <code class="literal">voice-code</code> and
            <code class="literal">tts-reset-code</code> to the
            speech server.</p>
          </div>
        </div>
        <div class="sect2" lang="en" xml:lang="en">
          <div class="titlepage">
            <h3 class="title"><a id=
            "using_aural_css_acss_for_styling_speech_output" name=
            "using_aural_css_acss_for_styling_speech_output"></a>Using
            Aural CSS (ACSS) for Styling Speech Output</h3>
          </div>
          <p>I first formalized audio formatting within AsTeR,
          where rendering rules were written in a specialized
          language called <a id="idx-CHP-31-2691" class="indexterm"
          name="idx-CHP-31-2691"></a>Audio Formatting Language (
          <a id="idx-CHP-31-2692" class="indexterm" name=
          "idx-CHP-31-2692"></a>AFL). AFL structured the available
          parameters in auditory space—e.g., the pitch of the
          speaking voice—into a multidimensional space, and
          encapsulated the state of the rendering engine as a point
          in this multidimensional space. <a id="idx-CHP-31-2693"
          class="indexterm" name="idx-CHP-31-2693"></a> <a id=
          "idx-CHP-31-2694" class="indexterm" name=
          "idx-CHP-31-2694"></a> <a id="idx-CHP-31-2695" class=
          "indexterm" name="idx-CHP-31-2695"></a></p>
          <p>AFL provided a block-structured language that
          encapsulated the current rendering state by a lexically
          scoped variable, and provided operators to move within
          this structured space. When these notions were later
          mapped to the declarative world of HTML and CSS,
          dimensions making up the AFL rendering state became Aural
          CSS parameters, provided as accessibility measures in
          <a id="idx-CHP-31-2696" class="indexterm" name=
          "idx-CHP-31-2696"></a>CSS2 ( <a href=
          "http://www.w3.org/Press/1998/CSS2-REC" target=
          "_top">http://www.w3.org/Press/1998/CSS2-REC</a>). <a id=
          "I_indexterm31_tt697" class="indexterm" name=
          "I_indexterm31_tt697"></a></p>
          <p>Though designed for styling HTML (and, in general,
          XML) markup trees, <a id="idx-CHP-31-2697" class=
          "indexterm" name="idx-CHP-31-2697"></a>Aural CSS turned
          out to be a good abstraction for building <a id=
          "idx-CHP-31-2698" class="indexterm" name=
          "idx-CHP-31-2698"></a>Emacspeak's audio formatting layer
          while keeping the implementation independent of any given
          TTS engine.</p>
          <p>Here is the definition of the <a id="idx-CHP-31-2699"
          class="indexterm" name="idx-CHP-31-2699"></a>data
          structure that encapsulates <a id="idx-CHP-31-2700"
          class="indexterm" name="idx-CHP-31-2700"></a>ACSS
          settings:</p><a id="I_programlisting31_tt698" name=
          "I_programlisting31_tt698"></a>
          <pre class="programlisting">
        (defstruct acss
          family gain left-volume right-volume
          average-
<a id="idx-CHP-31-2701" class="indexterm" name=
"idx-CHP-31-2701"></a>pitch 
<a id="idx-CHP-31-2702" class="indexterm" name=
"idx-CHP-31-2702"></a>pitch-range stress richness 
<a id="idx-CHP-31-2703" class="indexterm" name=
"idx-CHP-31-2703"></a>punctuations)

</pre>
          <p><a id="idx-CHP-31-2704" class="indexterm" name=
          "idx-CHP-31-2704"></a>Emacspeak provides a collection of
          predefined <span class="emphasis"><em>voice
          overlays</em></span> for use within <a id=
          "idx-CHP-31-2705" class="indexterm" name=
          "idx-CHP-31-2705"></a>speech extensions. Voice overlays
          are designed to <span class=
          "emphasis"><em>cascade</em></span> in the spirit of Aural
          CSS. As an example, here is the ACSS setting that
          corresponds to <code class=
          "literal">voice-monotone</code> : <a id="idx-CHP-31-2706"
          class="indexterm" name="idx-CHP-31-2706"></a> <a id=
          "idx-CHP-31-2707" class="indexterm" name=
          "idx-CHP-31-2707"></a></p><a id=
          "I_programlisting31_tt699" name=
          "I_programlisting31_tt699"></a>
          <pre class="programlisting">
        [cl-struct-acss nil nil nil nil nil 0 0 nil all]

</pre>
          <p>Notice that most fields of this <code class=
          "literal">acss</code> structure are <code class=
          "literal">nil</code> —that is, unset. The setting creates
          a voice overlay that:</p>
          <div class="orderedlist">
            <ol type="1">
              <li>
                <p>Sets <code class="literal">pitch</code> to 0 to
                create a flat voice.</p>
              </li>
              <li>
                <p>Sets <code class="literal">pitch-range</code> to
                0 to create a <a id="idx-CHP-31-2708" class=
                "indexterm" name="idx-CHP-31-2708"></a>monotone
                voice with no inflection.</p>
                <p>This setting is used as the value of the
                <code class="literal">personality</code> property
                for audio formatting comments in all programming
                language modes. Because its value is an overlay, it
                can interact effectively with other aural display
                properties. As an example, if portions of a comment
                are displayed in a bold font, those portions can
                have the <code class="literal">voice-bolden</code>
                personality (another predefined overlay) added;
                this results in setting the <code class=
                "literal">personality</code> property to a list of
                two values: ( <code class="literal">voice-bolden
                voice-monotone</code> ). The final effect is for
                the text to get spoken with a distinctive voice
                that conveys both aspects of the text: namely, a
                sequence of words that are emphasized within a
                comment.</p>
              </li>
              <li>
                <p>Sets <code class="literal">punctuations</code>
                to <code class="literal">all</code> so that all
                punctuation marks are spoken.</p>
              </li>
            </ol>
          </div>
        </div>
        <div class="sect2" lang="en" xml:lang="en">
          <div class="titlepage">
            <h3 class="title"><a id="adding_auditory_icons" name=
            "adding_auditory_icons"></a>Adding Auditory Icons</h3>
          </div>
          <p>Rich visual user interfaces contain both text and
          icons. Similarly, once Emacspeak had the ability to speak
          intelligently, the next step was to increase the
          bandwidth of aural communication by augmenting the output
          with auditory icons. <a id="idx-CHP-31-2709" class=
          "indexterm" name="idx-CHP-31-2709"></a> <a id=
          "idx-CHP-31-2710" class="indexterm" name=
          "idx-CHP-31-2710"></a></p>
          <p>Auditory icons in Emacspeak are short sound snippets
          (no more than two seconds in duration) and are used to
          indicate frequently occurring events in the user
          interface. As an example, every time the user saves a
          file, the system plays a confirmatory sound. Similarly,
          opening or closing an object (anything from a file to a
          web site) produces a corresponding auditory icon. The set
          of auditory icons were arrived at iteratively and cover
          common events such as objects being opened, closed, or
          deleted. This section describes how these auditory icons
          are injected into Emacspeak's output stream.</p>
          <p>Auditory icons are produced by the following <a id=
          "idx-CHP-31-2711" class="indexterm" name=
          "idx-CHP-31-2711"></a>user interactions:</p>
          <div class="itemizedlist">
            <ul type="disc">
              <li>
                <p>To cue explicit user actions</p>
              </li>
              <li>
                <p>To add additional cues to spoken <a id=
                "idx-CHP-31-2712" class="indexterm" name=
                "idx-CHP-31-2712"></a>output</p>
              </li>
            </ul>
          </div>
          <p><a id="idx-CHP-31-2713" class="indexterm" name=
          "idx-CHP-31-2713"></a>Auditory icons that confirm user
          actions—e.g., a file being saved successfully—are
          produced by adding an <code class="literal">after</code>
          <span class="emphasis"><em>advice</em></span> to the
          various <a id="idx-CHP-31-2714" class="indexterm" name=
          "idx-CHP-31-2714"></a>Emacs built-ins. To provide a
          consistent sound and feel across the <a id=
          "idx-CHP-31-2715" class="indexterm" name=
          "idx-CHP-31-2715"></a>Emacspeak desktop, such extensions
          are attached to code that is called from many places in
          Emacs.</p>
          <p>Here is an example of such an extension, implemented
          via an <span class="emphasis"><em>advice</em></span>
          fragment:</p><a id="I_programlisting31_tt700" name=
          "I_programlisting31_tt700"></a>
          <pre class="programlisting">
        (defadvice save-buffer (after emacspeak pre act)
          "Produce an auditory icon if possible."
          (when (interactive-p) (emacspeak-auditory-icon 'save-object)
            (or emacspeak-last-message (message "Wrote %s" (buffer-file-name)))))

</pre>
          <p>Extensions can also be implemented via an
          Emacs-provided hook. As explained in the brief
          <span class="emphasis"><em>advice</em></span> tutorial
          given earlier, <span class=
          "emphasis"><em>advice</em></span> allows the behavior of
          existing software to be extended or modified without
          having to modify the underlying source code. Emacs is
          itself an extensible system, and well-written Lisp code
          has a tradition of providing appropriate extension hooks
          for common use cases. As an example, Emacspeak attaches
          auditory feedback to Emacs' default prompting mechanism
          (the Emacs minibuffer) by adding the function
          <code class="literal">emacspeak-minibuffer-setup-hook</code>
          to Emacs' <code class=
          "literal">minibuffer-setup-hook</code> : <a id=
          "idx-CHP-31-2716" class="indexterm" name=
          "idx-CHP-31-2716"></a></p><a id=
          "I_programlisting31_tt701" name=
          "I_programlisting31_tt701"></a>
          <pre class="programlisting">
        (defun emacspeak-minibuffer-setup-hook ()
          "Actions to take when entering the minibuffer."
          (let ((inhibit-field-text-motion t))
            (when emacspeak-minibuffer-enter-auditory-icon
              (emacspeak-auditory-icon 'open-object))
            (tts-with-punctuations 'all (emacspeak-speak-buffer))))
        (add-hook 'minibuffer-setup-hook 'emacspeak-minibuffer-setup-hook)

</pre>
          <p>This is a good example of using built-in extensibility
          where available. However, Emac-speak uses <span class=
          "emphasis"><em>advice</em></span> in a lot of cases
          because the Emacspeak requirement of adding auditory
          feedback to <span class="emphasis"><em>all</em></span> of
          Emacs was not originally envisioned when Emacs was
          implemented. Thus, the Emacspeak implementation
          demonstrates a powerful technique for <span class=
          "emphasis"><em>discovering</em></span> <a id=
          "idx-CHP-31-2717" class="indexterm" name=
          "idx-CHP-31-2717"></a>extension points.</p>
          <p>Lack of an <span class=
          "emphasis"><em>advice</em></span> -like feature in a
          programming language often makes experimentation
          difficult, especially when it comes to discovering useful
          <a id="idx-CHP-31-2718" class="indexterm" name=
          "idx-CHP-31-2718"></a>extension points. This is because
          software engineers are faced with the following
          trade-off:</p>
          <div class="itemizedlist">
            <ul type="disc">
              <li>
                <p>Make the system arbitrarily extensible (and
                arbitrarily complex)</p>
              </li>
              <li>
                <p>Guess at some reasonable extension points and
                hardcode these</p>
              </li>
            </ul>
          </div>
          <p>Once extension points are implemented, experimenting
          with new ones requires rewriting existing code, and the
          resulting inertia often means that over time, such
          extension points remain mostly undiscovered. Lisp
          <span class="emphasis"><em>advice</em></span> , and its
          Java counterpart Aspects, offer software engineers the
          opportunity to experiment without worrying about
          adversely affecting an existing body of source code.</p>
        </div>
        <div class="sect2" lang="en" xml:lang="en">
          <div class="titlepage">
            <h3 class="title"><a id=
            "producing_auditory_icons_while_speaking_content" name=
            "producing_auditory_icons_while_speaking_content"></a>Producing
            Auditory Icons While Speaking Content</h3>
          </div>
          <p>In addition to using auditory icons to cue the results
          of user interaction, <a id="idx-CHP-31-2719" class=
          "indexterm" name="idx-CHP-31-2719"></a>Emacspeak uses
          auditory icons to augment what is being spoken. Examples
          of such auditory icons include: <a id="idx-CHP-31-2720"
          class="indexterm" name="idx-CHP-31-2720"></a></p>
          <div class="itemizedlist">
            <ul type="disc">
              <li>
                <p>A short icon at the beginning of paragraphs</p>
              </li>
              <li>
                <p>The auditory icon <code class=
                "literal">mark-object</code> when moving across
                source lines that have a breakpoint set on them
                <a id="idx-CHP-31-2721" class="indexterm" name=
                "idx-CHP-31-2721"></a></p>
              </li>
            </ul>
          </div>
          <p>Auditory icons are implemented by attaching the text
          property <code class=
          "literal">emacspeak-auditory-icon</code> with a value
          equal to the name of the auditory icon to be played on
          the relevant text. <a id="idx-CHP-31-2722" class=
          "indexterm" name="idx-CHP-31-2722"></a></p>
          <p>As an example, commands to set breakpoints in the
          Grand Unified Debugger <a id="idx-CHP-31-2723" class=
          "indexterm" name="idx-CHP-31-2723"></a>Emacs package
          (GUD) are <span class="emphasis"><em>adviced</em></span>
          to add the property <code class=
          "literal">emacspeak-auditory-icon</code> to the line
          containing the breakpoint. When the user moves across
          such a line, the function <code class=
          "literal">tts-format-text-and-speak</code> queues the
          auditory icon at the right point in the output
          stream.</p>
        </div>
        <div class="sect2" lang="en" xml:lang="en">
          <div class="titlepage">
            <h3 class="title"><a id=
            "the_calendar_enhancing_spoken_output_with_context-sensitive_sem"
            name=
            "the_calendar_enhancing_spoken_output_with_context-sensitive_sem">
            </a>The Calendar: Enhancing Spoken Output with
            Context-Sensitive Semantics</h3>
          </div>
          <p>To summarize the story so far, Emacspeak has the
          ability to: <a id="idx-CHP-31-2724" class="indexterm"
          name="idx-CHP-31-2724"></a> <a id="idx-CHP-31-2725"
          class="indexterm" name="idx-CHP-31-2725"></a></p>
          <div class="itemizedlist">
            <ul type="disc">
              <li>
                <p>Produce auditory output from within the context
                of an application</p>
              </li>
              <li>
                <p>Audio-format output to increase the bandwidth of
                spoken communication</p>
              </li>
              <li>
                <p>Augment spoken output with auditory icons</p>
              </li>
            </ul>
          </div>
          <p>This section explains some of the enhancements that
          the design makes possible.</p>
          <p>I started implementing Emacspeak in October 1994 as a
          quick means of developing a <a id="idx-CHP-31-2726"
          class="indexterm" name="idx-CHP-31-2726"></a>speech
          solution for Linux. It was when I speech-enabled the
          Emacs Calendar in the first week of November 1994 that I
          realized that in fact I had created something far better
          than any other speech-access solution I had used
          before.</p>
          <p>A calendar is a good example of using a specific type
          of visual layout that is optimized both for the visual
          medium as well as for the information that is being
          conveyed. We intuitively think in terms of weeks and
          months when reasoning about dates; using a tabular layout
          that organizes dates in a grid with each week appearing
          on a row by itself matches this perfectly. With this form
          of layout, the human eye can rapidly move by days, weeks,
          or months through the calendar and easily answer such
          questions as "What day is it tomorrow?" and "Am I free on
          the third Wednesday of next month?"</p>
          <p>Notice, however, that simply speaking this
          two-dimensional layout does not transfer the efficiencies
          achieved in the visual context to auditory interaction.
          This is a good example of where the right auditory
          feedback has to be generated directly from the underlying
          information being conveyed, rather than from its visual
          representation. When <a id="idx-CHP-31-2727" class=
          "indexterm" name="idx-CHP-31-2727"></a>producing auditory
          output from visually formatted information, one has to
          <span class="emphasis"><em>rediscover</em></span> the
          underlying semantics of the information before speaking
          it.</p>
          <p>In contrast, when producing <a id="idx-CHP-31-2728"
          class="indexterm" name="idx-CHP-31-2728"></a>spoken
          feedback via <span class=
          "emphasis"><em>advice</em></span> definitions that extend
          the under-lying application, one has full access to the
          application's runtime context. Thus, rather than
          <span class="emphasis"><em>guessing</em></span> based on
          visual layout, one can essentially instruct the
          underlying application to <span class=
          "emphasis"><em>speak the right thing</em></span> !</p>
          <p>The <code class="literal">emacspeak-calendar</code>
          module <a id="idx-CHP-31-2729" class="indexterm" name=
          "idx-CHP-31-2729"></a>speech-enables the <a id=
          "idx-CHP-31-2730" class="indexterm" name=
          "idx-CHP-31-2730"></a>Emacs Calendar by defining utility
          functions that speak calendar information and advising
          all calendar navigation commands to call these functions.
          Thus, Emacs Calendar produces specialized behavior by
          binding the arrow keys to calendar navigation commands
          rather than the default cursor navigation found in
          regular editing modes. Emacspeak specializes this
          behavior by advising the calendar-specific commands to
          speak the relevant information in the context of the
          calendar. <a id="idx-CHP-31-2731" class="indexterm" name=
          "idx-CHP-31-2731"></a> <a id="idx-CHP-31-2732" class=
          "indexterm" name="idx-CHP-31-2732"></a></p>
          <p>The net effect is that from an end user's perspective,
          <span class="emphasis"><em>things just work</em></span> .
          In regular editing modes, pressing up/down arrows speaks
          the current line; pressing up/down arrows in the calendar
          navigates by weeks and speaks the current date.</p>
          <p>The <code class=
          "literal">emacspeak-calendar-speak-date</code> function,
          defined in the <code class=
          "literal">emacspeak-calendar</code> module, is shown
          here. Notice that it uses all of the facilities described
          so far to access and audio-format the relevant contextual
          information from the calendar: <a id="idx-CHP-31-2733"
          class="indexterm" name="idx-CHP-31-2733"></a></p><a id=
          "I_programlisting31_tt702" name=
          "I_programlisting31_tt702"></a>
          <pre class="programlisting">
        (defsubst 
<a id="idx-CHP-31-2734" class="indexterm" name=
"idx-CHP-31-2734"></a>emacspeak-calendar-entry-marked-p( )
          (member 'diary (mapcar #'overlay-face (overlays-at (point)))))
        (defun 
<a id="idx-CHP-31-2735" class="indexterm" name=
"idx-CHP-31-2735"></a>emacspeak-calendar-speak-date( )
          "Speak the date under point when called in Calendar Mode. "
          (let ((date (calendar-date-string (calendar-cursor-to-date t))))
            (cond
             ((emacspeak-calendar-entry-marked-p) (tts-speak-using-voice mark-personality
        date))
             (t (tts-speak date)))))

</pre>
          <p>Emacs marks dates that have a diary entry with a
          special overlay. In the previous definition, the helper
          function <code class=
          "literal">emacspeak-calendar-entry-marked-p</code> checks
          this overlay to implement a predicate that can be used to
          test if a date has a diary entry. The <code class=
          "literal">emacspeak-calendar-speak-date</code> function
          uses this predicate to decide whether the date needs to
          be rendered in a different voice; dates that have
          calendar entries are spoken using the <code class=
          "literal">mark-personality</code> voice. Notice that the
          <code class=
          "literal">emacspeak-calendar-speak-date</code> function
          accesses the calendar's runtime context in the
          call:</p><a id="I_programlisting31_tt703" name=
          "I_programlisting31_tt703"></a>
          <pre class="programlisting">
        (calendar-date-string (calendar-cursor-to-date t))

</pre>
          <p>The <code class=
          "literal">emacspeak-calendar-speak-date</code> function
          is called from <span class=
          "emphasis"><em>advice</em></span> <a id="idx-CHP-31-2736"
          class="indexterm" name="idx-CHP-31-2736"></a>definitions
          attached to all calendar navigation functions. Here is
          the <span class="emphasis"><em>advice</em></span>
          definition for function <code class=
          "literal">calendar-forward-week</code> : <a id=
          "idx-CHP-31-2737" class="indexterm" name=
          "idx-CHP-31-2737"></a></p><a id=
          "I_programlisting31_tt704" name=
          "I_programlisting31_tt704"></a>
          <pre class="programlisting">
        (defadvice calendar-forward-week (after emacspeak pre act)
          "Speak the date. "
          (when (interactive-p) (emacspeak-speak-calendar-date )
            (emacspeak-auditory-icon 'large-movement)))

</pre>
          <p>This is an <code class="literal">after</code>
          <span class="emphasis"><em>advice</em></span> , because
          we want the spoken feedback to be produced <span class=
          "emphasis"><em>after</em></span> the original navigation
          command has done its work.</p>
          <p>The body of the <span class=
          "emphasis"><em>advice</em></span> definition first calls
          the function <code class=
          "literal">emacspeak-calendar-speak-date</code> to speak
          the date under the cursor; next, it calls <code class=
          "literal">emacspeak-auditory-icon</code> to produce a
          short sound indicating that we have successfully moved.
          <a id="idx-CHP-31-2738" class="indexterm" name=
          "idx-CHP-31-2738"></a></p>
        </div>
      </div>
      <div class="sect1" lang="en" xml:lang="en">
        <div class="titlepage">
          <h2 class="title c2"><a id=
          "painless_access_to_online_information" name=
          "painless_access_to_online_information"></a>31.3.&nbsp;Painless
          Access to Online Information</h2>
        </div>
        <p>With all the necessary affordances to generate rich
        auditory output in place, <a id="idx-CHP-31-2739" class=
        "indexterm" name="idx-CHP-31-2739"></a>speech-enabling
        Emacs applications using Emacs Lisp's <span class=
        "emphasis"><em>advice</em></span> facility requires
        surprisingly small amounts of specialized code. With the
        TTS layer and the Emacspeak core handling the complex
        details of producing good quality output, the <a id=
        "idx-CHP-31-2740" class="indexterm" name=
        "idx-CHP-31-2740"></a>speech-enabling extensions focus
        purely on the specialized <a id="idx-CHP-31-2741" class=
        "indexterm" name="idx-CHP-31-2741"></a>semantics of
        individual applications; this leads to simple and
        consequently <span class=
        "emphasis"><em>beautiful</em></span> code. This section
        illustrates the concept with a few choice examples taken
        from Emacspeak's rich suite of information access tools.
        <a id="idx-CHP-31-2742" class="indexterm" name=
        "idx-CHP-31-2742"></a></p>
        <p>Right around the time I started Emacspeak, a far more
        profound revolution was taking place in the world of
        computing: the World Wide Web went from being a tool for
        academic research to a mainstream forum for everyday tasks.
        This was 1994, when writing a browser was still a
        comparatively easy task. The complexity that has been
        progressively added to the Web in the subsequent 12 years
        often tends to obscure the fact that the Web is still a
        fundamentally simple design where:</p>
        <div class="itemizedlist">
          <ul type="disc">
            <li>
              <p>Content creators publish web resources addressable
              via URIs.</p>
            </li>
            <li>
              <p>URI-addressable content is retrievable via open
              protocols.</p>
            </li>
            <li>
              <p>Retrieved content is in HTML, a well-understood
              markup language.</p>
            </li>
          </ul>
        </div>
        <p>Notice that the basic architecture just sketched out
        says little to nothing about how the content is made
        available to the end user. The mid-1990s saw the Web move
        toward increasingly complex visual interaction. The
        commercial Web with its penchant for flashy visual
        interaction increasingly moved away from the simple
        data-oriented interaction that had characterized early web
        sites. By 1998, I found that the Web had a lot of useful
        interactive sites; to my dismay, I also found that I was
        using progressively fewer of these sites because of the
        time it took to complete tasks when using <a id=
        "idx-CHP-31-2743" class="indexterm" name=
        "idx-CHP-31-2743"></a>spoken output.</p>
        <p>This led me to create a suite of <a id="idx-CHP-31-2744"
        class="indexterm" name="idx-CHP-31-2744"></a>web-oriented
        tools within Emacspeak that went back to the basics of web
        interaction. Emacs was already capable of rendering simple
        HTML into interactive hypertext documents. As the Web
        became complex, Emacspeak acquired a collection of
        interaction wizards built on top of Emacs' HTML rendering
        capability that progressively factored out the complexity
        of web interaction to create an auditory interface that
        allowed the user to quickly and painlessly listen to
        desired information. <a id="I_indexterm31_tt705" class=
        "indexterm" name="I_indexterm31_tt705"></a> <a id=
        "I_indexterm31_tt706" class="indexterm" name=
        "I_indexterm31_tt706"></a> <a id="I_indexterm31_tt707"
        class="indexterm" name="I_indexterm31_tt707"></a></p>
        <div class="sect2" lang="en" xml:lang="en">
          <div class="titlepage">
            <h3 class="title"><a id=
            "basic_html_with_emacs_w3_and_aural_css" name=
            "basic_html_with_emacs_w3_and_aural_css"></a>Basic HTML
            with Emacs W3 and Aural CSS</h3>
          </div>
          <p>Emacs W3 is a bare-bones web browser first implemented
          in the mid-1990s. Emacs W3 implemented CSS (Cascading
          Style Sheets) <a id="idx-CHP-31-2745" class="indexterm"
          name="idx-CHP-31-2745"></a>early on, and this was the
          basis of the first Aural CSS implementation, which was
          released at the time I wrote the Aural CSS draft in
          February 1996. <a id="idx-CHP-31-2746" class="indexterm"
          name="idx-CHP-31-2746"></a>Emacspeak speech-enables Emacs
          W3 via the <code class="literal">emacspeak-w3</code>
          module, which implements the following extensions: <a id=
          "idx-CHP-31-2747" class="indexterm" name=
          "idx-CHP-31-2747"></a> <a id="idx-CHP-31-2748" class=
          "indexterm" name="idx-CHP-31-2748"></a> <a id=
          "idx-CHP-31-2749" class="indexterm" name=
          "idx-CHP-31-2749"></a></p>
          <div class="itemizedlist">
            <ul type="disc">
              <li>
                <p>An <code class="literal">aural media</code>
                section in the default stylesheet for Aural
                CSS.</p>
              </li>
              <li>
                <p><span class="emphasis"><em>advice</em></span>
                added to all interactive commands to produce
                auditory feedback.</p>
              </li>
              <li>
                <p>Special patterns to recognize and silence
                decorative images on web pages.</p>
              </li>
              <li>
                <p>Aural rendering of HTML form fields along with
                the associated <code class="literal">label</code> ,
                which underlay the design of the <code class=
                "literal">label</code> element in HTML 4.</p>
              </li>
              <li>
                <p>Context-sensitive rendering rules for HTML form
                controls. As an example, given a group of radio
                buttons for answering the question:</p>
                <table class="simplelist" border="0" summary=
                "Simple list">
                  <tr>
                    <td>Do you accept?</td>
                  </tr>
                </table>
                <p>Emacspeak extends Emacs W3 to produce a spoken
                message of the form:</p>
                <table class="simplelist" border="0" summary=
                "Simple list">
                  <tr>
                    <td>Radio group <code class="literal">Do you
                    accept?</code> has <code class=
                    "literal">Yes</code> pressed.</td>
                  </tr>
                </table>
                <p>and:</p>
                <table class="simplelist" border="0" summary=
                "Simple list">
                  <tr>
                    <td>Press this to change radio group
                    <code class="literal">Do you accept?</code>
                    from <code class="literal">Yes</code> to
                    <code class="literal">No</code> .</td>
                  </tr>
                </table>
              </li>
              <li>
                <p>A <code class="literal">before</code> advice
                defined for the Emacs W3 function <code class=
                "literal">w3-parse-buffer</code> that applies
                user-requested XSLT transforms to HTML pages.</p>
              </li>
            </ul>
          </div>
        </div>
        <div class="sect2" lang="en" xml:lang="en">
          <div class="titlepage">
            <h3 class="title"><a id=
            "the_emacspeak-websearch_module_for_task-oriented_search"
            name=
            "the_emacspeak-websearch_module_for_task-oriented_search">
            </a>The emacspeak-websearch Module for Task-Oriented
            Search</h3>
          </div>
          <p><a id="idx-CHP-31-2750" class="indexterm" name=
          "idx-CHP-31-2750"></a>By 1997, interactive sites on the
          Web, ranging from Altavista for searching to Yahoo! Maps
          for <a id="idx-CHP-31-2751" class="indexterm" name=
          "idx-CHP-31-2751"></a>online directions, required the
          user to go through a highly visual process that included:
          <a id="idx-CHP-31-2752" class="indexterm" name=
          "idx-CHP-31-2752"></a></p>
          <div class="orderedlist">
            <ol type="1">
              <li>
                <p>Filling in a set of form fields</p>
              </li>
              <li>
                <p>Submitting the resulting form</p>
              </li>
              <li>
                <p>Spotting the results in the resulting complex
                HTML page</p>
              </li>
            </ol>
          </div>
          <p>The first and third of these steps were the ones that
          took time when using spoken output. I needed to first
          locate the various form fields on a visually busy page
          and wade through a lot of complex boilerplate material on
          result pages before I found the answer.</p>
          <p>Notice that from the software design point of view,
          these steps neatly map into <span class=
          "emphasis"><em>pre-action</em></span> and <span class=
          "emphasis"><em>post-action</em></span> hooks. Because web
          interaction follows a very simple architecture based on
          URIs, the pre-action step of prompting the user for the
          right pieces of input can be factored out of a web site
          and placed in a small piece of code that runs locally;
          this obviates the need for the user to open the initial
          launch page and seek out the various input fields. <a id=
          "idx-CHP-31-2753" class="indexterm" name=
          "idx-CHP-31-2753"></a></p>
          <p>Similarly, the post-action step of spotting the actual
          results amid the rest of the noise on the resulting page
          can also be delegated to software.</p>
          <p>Finally, notice that even though these pre-action and
          post-action steps are each specific to particular web
          sites, the overall design pattern is one that can be
          generalized. This insight led to the <code class=
          "literal">emacspeak-websearch</code> module, a collection
          of task-oriented web <a id="idx-CHP-31-2754" class=
          "indexterm" name="idx-CHP-31-2754"></a>tools that: <a id=
          "idx-CHP-31-2755" class="indexterm" name=
          "idx-CHP-31-2755"></a></p>
          <div class="orderedlist">
            <ol type="1">
              <li>
                <p>Prompted the user</p>
              </li>
              <li>
                <p>Constructed an appropriate URI and pulled the
                content at that URI</p>
              </li>
              <li>
                <p>Filtered the result before rendering the
                relevant content via Emacs W3</p>
              </li>
            </ol>
          </div>
          <p>Here is the <code class=
          "literal">emacspeak-websearch</code> tool for accessing
          directions from <a id="idx-CHP-31-2756" class="indexterm"
          name="idx-CHP-31-2756"></a>Yahoo! Maps: <a id=
          "idx-CHP-31-2757" class="indexterm" name=
          "idx-CHP-31-2757"></a></p><a id=
          "I_programlisting31_tt708" name=
          "I_programlisting31_tt708"></a>
          <pre class="programlisting">
        (defsubst 
<a id="idx-CHP-31-2758" class="indexterm" name=
"idx-CHP-31-2758"></a>emacspeak-websearch-yahoo-map-directions-get-locations ( )
          "Convenience 
<a id="idx-CHP-31-2759" class="indexterm" name=
"idx-CHP-31-2759"></a>function for prompting and constructing the route component."
          (concat
           (format "&amp;newaddr=%s"
                   (emacspeak-url-encode (read-from-minibuffer "Start Address: ")))
           (format "&amp;newcsz=%s"
                   (emacspeak-url-encode (read-from-minibuffer "City/State or Zip:")))
           (format "&amp;newtaddr=%s"
                   (emacspeak-url-encode (read-from-minibuffer "Destination Address: ")))
           (format "&amp;newtcsz=%s"
                   (emacspeak-url-encode (read-from-minibuffer "City/State or Zip:")))))
        (defun emacspeak-websearch-yahoo-map-directions-search (query )
          "Get driving directions from Yahoo."
          (interactive
           (list (emacspeak-websearch-yahoo-map-directions-get-locations))
           (emacspeak-w3-extract-table-by-match
            "Start"
            (concat emacspeak-websearch-yahoo-maps-uri query))))

</pre>
          <p>A brief explanation of the previous code follows:</p>
          <div class="variablelist">
            <dl>
              <dt><span class=
              "term emphasis"><em>Pre-action</em></span></dt>
              <dd>
                <p>The <code class=
                "literal">emacspeak-websearch-yahoo-map-directions-get-locations</code>
                function prompts the user for the start and end
                locations. Notice that this function hardwires the
                names of the query parameters used by Yahoo! Maps.
                On the surface, this looks like a kluge that is
                guaranteed to break. In fact, this kluge has not
                broken since it was first defined in 1997. The
                reason is obvious: once a web application has
                published a set of query parameters, those
                parameters get hardcoded in a number of places,
                including within a large number of HTML pages on
                the originating web site. Depending on parameter
                names may feel brittle to the software architect
                used to structured, top-down APIs, but the use of
                such URL parameters to define bottom-up web
                services leads to the notion of RESTful web
                APIs.</p>
              </dd>
              <dt><span class="term emphasis"><em>Retrieve
              content</em></span></dt>
              <dd>
                <p>The URL for retrieving directions is constructed
                by concatenating the user input to the <span class=
                "emphasis"><em>base URI</em></span> for Yahoo!
                Maps.</p>
              </dd>
              <dt><span class=
              "term emphasis"><em>Post-action</em></span></dt>
              <dd>
                <p>The resulting URI is passed to the function
                <code class=
                "literal">emacspeak-w3-extract-table-by-match</code>
                along with a search pattern <code class=
                "literal">Start</code> to: <a id="idx-CHP-31-2760"
                class="indexterm" name="idx-CHP-31-2760"></a></p>
                <div class="itemizedlist">
                  <ul type="disc">
                    <li>
                      <p>Retrieve the content using Emacs W3.</p>
                    </li>
                    <li>
                      <p>Apply an XSLT transform to extract the
                      table containing <code class=
                      "literal">Start</code> .</p>
                    </li>
                    <li>
                      <p>Render this table using Emacs W3's HTML
                      formatter.</p>
                    </li>
                  </ul>
                </div>
                <p>Unlike the query parameters, the layout of the
                results page <span class=
                "emphasis"><em>does</em></span> change about once a
                year, on average. But keeping this tool current
                with Yahoo! Maps comes down to maintaining the
                post-action portion of this utility. In over eight
                years of use, I have had to modify it about half a
                dozen times, and given that the underlying platform
                provides many of the <a id="idx-CHP-31-2761" class=
                "indexterm" name="idx-CHP-31-2761"></a>tools for
                filtering the result page, the actual lines of code
                that need to be written for each layout change is
                minimal.</p>
                <p>The <code class=
                "literal">emacspeak-w3-extract-table-by-match</code>
                function uses an XSLT transformation that filters a
                document to return tables that contain a specified
                search pattern. For this example, the function
                constructs the following XPath expression: <a id=
                "idx-CHP-31-2762" class="indexterm" name=
                "idx-CHP-31-2762"></a></p><a id=
                "I_programlisting31_tt709" name=
                "I_programlisting31_tt709"></a>
                <pre class="programlisting">
        (/descendant::table[contains(., Start)])[last( )]

</pre>
                <p>This effectively picks out the list of tables
                that contain the string <code class=
                "literal">Start</code> and returns the last element
                of that list.</p>
              </dd>
            </dl>
          </div>
          <p>Seven years after this utility was written, Google
          launched <a id="idx-CHP-31-2763" class="indexterm" name=
          "idx-CHP-31-2763"></a>Google Maps to great excitement in
          February 2005. Many blogs on the Web put Google Maps
          under the microscope and quickly discovered the query
          parameters used by that application. I used that to build
          a corresponding Google Maps tool in Emacspeak that
          provides similar functionality. The user experience is
          smoother with the Google Maps tool because the start and
          end locations can be specified within the same parameter.
          Here is the code for the Google Maps wizard:</p><a id=
          "I_programlisting31_tt710" name=
          "I_programlisting31_tt710"></a>
          <pre class="programlisting">
        (defun 
<a id="idx-CHP-31-2764" class="indexterm" name=
"idx-CHP-31-2764"></a>emacspeak-websearch-emaps-search (query &amp;optional use-near)
          "Perform EmapSpeak search. Query is in plain English."
          (interactive
           (list
            (emacspeak-websearch-read-query
             (if current-prefix-arg
                 (format "Find what near %s: "
                         emacspeak-websearch-emapspeak-my-location)
               "EMap Query: "))
            current-prefix-arg))
          (let ((near-p ;; determine query type
                 (unless use-near
                   (save-match-data (and (string-match "near" query) (match-end 0)))))
                (near nil)
                (uri nil))
            (when near-p ;; determine location from query
              (setq near (substring query near-p))
              (setq emacspeak-websearch-emapspeak-my-location near))
            (setq uri
                  (cond
                   (use-near
                    (format 
<a id="idx-CHP-31-2765" class="indexterm" name=
"idx-CHP-31-2765"></a>emacspeak-websearch-google-maps-uri
                            (emacspeak-url-encode
                             (format "%s near %s" query near))))
                   (t (format 
<a id="idx-CHP-31-2766" class="indexterm" name=
"idx-CHP-31-2766"></a>emacspeak-websearch-google-maps-uri
                             (emacspeak-url-encode query)))))
            (add-hook 'emacspeak-w3-post-process-hook 'emacspeak-speak-buffer)
            (add-hook 'emacspeak-w3-post-process-hook
                      #'(lambda nil
                          (emacspeak-pronounce-add-buffer-local-dictionary-entry
                           "ðmi" " miles ")))
            (browse-url-of-buffer
             (emacspeak-xslt-xml-url
              (expand-file-name "kml2html.xsl" emacspeak-xslt-directory)
              uri))))

</pre>
          <p>A brief explanation of the code follows:</p>
          <div class="orderedlist">
            <ol type="1">
              <li>
                <p>Parse the input to decide whether it's a
                direction or a search query.</p>
              </li>
              <li>
                <p>In case of search queries, cache the user's
                location for future use.</p>
              </li>
              <li>
                <p>Construct a URI for retrieving results.</p>
              </li>
              <li>
                <p>Browse the results of filtering the contents of
                the URI through the XSLT filter <code class=
                "literal">kml2html</code> , which converts the
                retrieved content into a simple hypertext
                document.</p>
              </li>
              <li>
                <p>Set up custom pronunciations in the results to
                pronounce <code class="literal">mi</code> as
                "miles."</p>
              </li>
            </ol>
          </div>
          <p>Notice that, as before, most of the code focuses on
          application-specific tasks. Rich spoken output is
          produced by creating the results as a well-structured
          HTML document with the appropriate Aural CSS rules
          producing an audio-formatted presentation.</p>
        </div>
        <div class="sect2" lang="en" xml:lang="en">
          <div class="titlepage">
            <h3 class="title"><a id=
            "the_web_command_line_and_url_templates" name=
            "the_web_command_line_and_url_templates"></a>The Web
            Command Line and URL Templates</h3>
          </div>
          <p>With more and more services becoming available on the
          Web, another useful pattern emerged by early 2000: <a id=
          "idx-CHP-31-2767" class="indexterm" name=
          "idx-CHP-31-2767"></a>web sites started creating smart
          client-side interaction via Java-Script. One typical use
          of such scripts was to construct URLs on the clientside
          for accessing specific pieces of content based on user
          input. As examples, Major League Baseball constructs the
          URL for retrieving scores for a given game by piecing
          together the date and the names of the home and visiting
          teams, and NPR creates URLs by piecing together the date
          with the program code of a given NPR show. <a id=
          "idx-CHP-31-2768" class="indexterm" name=
          "idx-CHP-31-2768"></a> <a id="idx-CHP-31-2769" class=
          "indexterm" name="idx-CHP-31-2769"></a></p>
          <p>To enable fast access to such services, I added an
          <code class="literal">emacspeak-url-template</code>
          module in late 2000. This module has become a powerful
          companion to the <code class=
          "literal">emacspeak-websearch</code> module described in
          the previous section. Together, these modules turn the
          Emacs minibuffer into a powerful web command line that
          provides rapid access to web content. <a id=
          "idx-CHP-31-2770" class="indexterm" name=
          "idx-CHP-31-2770"></a></p>
          <p>Many web services require the user to specify a date.
          One can usefully default the date by using the user's
          calendar to provide the context. Thus, Emacspeak <a id=
          "idx-CHP-31-2771" class="indexterm" name=
          "idx-CHP-31-2771"></a>tools for playing an NPR program or
          retrieving MLB scores default to using the date under the
          cursor when invoked from within the Emacs calendar
          buffer. <a id="I_indexterm31_tt711" class="indexterm"
          name="I_indexterm31_tt711"></a></p>
          <p>URL templates in <a id="idx-CHP-31-2772" class=
          "indexterm" name="idx-CHP-31-2772"></a>Emacspeak are
          implemented using the following data structure:</p><a id=
          "I_programlisting31_tt712" name=
          "I_programlisting31_tt712"></a>
          <pre class="programlisting">
        (defstruct (emacspeak-url-template (:constructor emacspeak-ut-constructor))
          name                                  ;; Human-readable name
          template                              ;; template URL string
          generators;; list of param generator
          post-action                    ;; action to perform after opening
          documentation                         ;; resource documentation
          fetcher)

</pre>
          <p>Users invoke URL templates via the Emacspeak command
          <code class="literal">emacspeak-url-template-fetch</code>
          command, which prompts for a URL template and: <a id=
          "idx-CHP-31-2773" class="indexterm" name=
          "idx-CHP-31-2773"></a></p>
          <div class="orderedlist">
            <ol type="1">
              <li>
                <p>Looks up the named template.</p>
              </li>
              <li>
                <p>Prompts the user by calling the specified
                <code class="literal">generator</code> .</p>
              </li>
              <li>
                <p>Applies the Lisp function <code class=
                "literal">format</code> to the template string and
                the collected arguments to create the final
                URI.</p>
              </li>
              <li>
                <p>Sets up any <span class="emphasis"><em>post
                actions</em></span> performed after the content has
                been rendered.</p>
              </li>
              <li>
                <p>Applies the specified fetcher to render the
                content.</p>
              </li>
            </ol>
          </div>
          <p>The use of this structure is best explained with an
          example. The following is the URL template for playing
          <a id="idx-CHP-31-2774" class="indexterm" name=
          "idx-CHP-31-2774"></a>NPR programs:</p><a id=
          "I_programlisting31_tt713" name=
          "I_programlisting31_tt713"></a>
          <pre class="programlisting">
        (emacspeak-url-template-define
         "NPR On Demand"
         "http://www.npr.org/dmg/dmg.php?prgCode=%s&amp;showDate=%s&amp;segNum=%s&amp;mediaPref=RM"
         (list
          #'(lambda ( ) (upcase (read-from-minibuffer "Program code:")))
          #'(lambda ( )
              (emacspeak-url-template-collect-date "Date:" "%d-%b-%Y"))
          "Segment:")
         nil; no post actions
         "Play NPR shows on demand.
        Program is specified as a program code:
        ME              Morning Edition
        ATC             All Things Considered
        day             Day To Day
        newsnotes       News And Notes
        totn            Talk Of The Nation
        fa              Fresh Air
        wesat           Weekend Edition Saturday
        wesun           Weekend Edition Sunday
        fool            The Motley Fool
        Segment is specified as a two digit number --specifying a blank value
        plays entire program."
         #'(lambda (url)
             (funcall emacspeak-media-player url 'play-list)
             (emacspeak-w3-browse-xml-url-with-style
              (expand-file-name "smil-anchors.xsl" emacspeak-xslt-directory)
              url)))

</pre>
          <p>In this example, the custom <code class=
          "literal">fetcher</code> performs two actions:</p>
          <div class="orderedlist">
            <ol type="1">
              <li>
                <p>Launches a media player to start playing the
                audio stream.</p>
              </li>
              <li>
                <p>Filters the associated SMIL document via the
                XSLT file <span class=
                "emphasis"><em>smil-anchors.xsl</em></span> .</p>
              </li>
            </ol>
          </div>
        </div>
        <div class="sect2" lang="en" xml:lang="en">
          <div class="titlepage">
            <h3 class="title"><a id="the_advent_of_feed_readers"
            name="the_advent_of_feed_readers"></a>The Advent of
            Feed Readers</h3>
          </div>
          <p>When I implemented the <code class=
          "literal">emacspeak-websearch</code> and <code class=
          "literal">emacspeak-url-template</code> modules,
          Emacspeak needed to screen-scrape HTML pages to speak the
          relevant <a id="idx-CHP-31-2775" class="indexterm" name=
          "idx-CHP-31-2775"></a>information. But as the Web grew in
          complexity, the need to readily get beyond the
          superficial presentation of pages to the real content
          took on a wider value than eyes-free access. Even users
          capable of working with complex visual interfaces found
          themselves under a serious information overload. This led
          to the advent of RSS and <a id="idx-CHP-31-2776" class=
          "indexterm" name="idx-CHP-31-2776"></a>Atom feeds, and
          the concomitant arrival of <a id="idx-CHP-31-2777" class=
          "indexterm" name="idx-CHP-31-2777"></a>feed reading
          software. <a id="idx-CHP-31-2778" class="indexterm" name=
          "idx-CHP-31-2778"></a></p>
          <p>These developments have had a very positive effect on
          the Emacspeak code base. During the past few years, the
          code has become <span class="emphasis"><em>more
          beautiful</em></span> as I have progressively deleted
          screen-scraping logic and replaced it with direct content
          access. As an example, here is the Emacspeak URL template
          for <a id="idx-CHP-31-2779" class="indexterm" name=
          "idx-CHP-31-2779"></a>retrieving the weather for a given
          city/state:</p><a id="I_programlisting31_tt714" name=
          "I_programlisting31_tt714"></a>
          <pre class="programlisting">
        (emacspeak-url-template-define
         "rss weather from wunderground"
         "http://www.wunderground.com/auto/rss_full/%s.xml?units=both"
         (list "State/City e.g.: MA/Boston") nil
         "Pull RSS weather feed for specified state/city."
         'emacspeak-rss-display)

</pre>
          <p>And here is the URL template for <a id=
          "idx-CHP-31-2780" class="indexterm" name=
          "idx-CHP-31-2780"></a>Google News searches via Atom
          feeds:</p><a id="I_programlisting31_tt715" name=
          "I_programlisting31_tt715"></a>
          <pre class="programlisting">
        (emacspeak-url-template-define
         "Google News Search"
         "http://news.google.com/news?hl=en&amp;ned=tus&amp;q=%s&amp;btnG=Google+Search&amp;output=atom"
         (list "Search news for: ") nil "Search Google news."
         'emacspeak-atom-display )

</pre>
          <p>Both of these <a id="idx-CHP-31-2781" class=
          "indexterm" name="idx-CHP-31-2781"></a>tools use all of
          the facilities provided by the <code class=
          "literal">emacspeak-url-template</code> module and
          consequently need to do very little on their own.
          Finally, notice that by relying on standardized feed
          formats such as <a id="idx-CHP-31-2782" class="indexterm"
          name="idx-CHP-31-2782"></a>RSS and Atom, these templates
          now have very little in the way of site-specific kluges,
          in contrast to older tools like the Yahoo! Maps wizard,
          which hardwired specific patterns from the results
          page.</p>
        </div>
      </div>
      <div class="sect1" lang="en" xml:lang="en">
        <div class="titlepage">
          <h2 class="title c2"><a id="summary" name=
          "summary"></a>31.4.&nbsp;Summary</h2>
        </div>
        <p>Emacspeak was conceived as a full-fledged, eyes-free
        user interface to everyday computing tasks. To be
        <span class="emphasis"><em>full-fledged</em></span> , the
        system needed to provide direct access to every aspect of
        computing on desktop workstations. To enable fluent
        <span class="emphasis"><em>eyes-free</em></span>
        interaction, the system needed to treat spoken output and
        the auditory medium as a first-class citizen—i.e., merely
        reading out information displayed on the screen was not
        sufficient. <a id="I_indexterm31_tt716" class="indexterm"
        name="I_indexterm31_tt716"></a> <a id="I_indexterm31_tt717"
        class="indexterm" name="I_indexterm31_tt717"></a></p>
        <p>To provide a <span class="emphasis"><em>complete audio
        desktop</em></span> , the target environment needed to be
        an interaction framework that was both widely deployed and
        fully extensible. To be able to do more than just speak the
        screen, the system needed to build interactive speech
        capability into the various applications.</p>
        <p>Finally, this had to be done without modifying the
        source code of any of the underlying applications; the
        project could not afford to fork a suite of applications in
        the name of adding eyes-free interaction, because I wanted
        to limit myself to the task of maintaining the speech
        extensions.</p>
        <p>To meet all these design requirements, I picked Emacs as
        the user interaction environment. As an interaction
        framework, Emacs had the advantage of having a very large
        developer community. Unlike other popular interaction
        frameworks available in 1994 when I began the project, it
        had the significant advantage of being a free software
        environment. (Now, 12 years later, Firefox affords similar
        opportunities.)</p>
        <p>The enormous flexibility afforded by Emacs Lisp as an
        extension language was an essential prerequisite in
        speech-enabling the various applications. The open source
        nature of the platform was just as crucial; even though I
        had made an explicit decision that I would modify no
        existing code, being able to study how various applications
        were implemented made speech-enabling them tractable.
        Finally, the availability of a high-quality <span class=
        "emphasis"><em>advice</em></span> implementation for Emacs
        Lisp (note that Lisp's <span class=
        "emphasis"><em>advice</em></span> facility was the prime
        motivator behind Aspect Oriented Programming) made it
        possible to speech-enable applications authored in Emacs
        Lisp without modifying the original source code.</p>
        <p><a id="idx-CHP-31-2783" class="indexterm" name=
        "idx-CHP-31-2783"></a>Emacspeak is a direct consequence of
        the matching up of the needs previously outlined and the
        affordances provided by Emacs as a user interaction
        environment.</p>
        <div class="sect2" lang="en" xml:lang="en">
          <div class="titlepage">
            <h3 class="title"><a id=
            "managing_code_complexity_over_time" name=
            "managing_code_complexity_over_time"></a>Managing Code
            Complexity Over Time</h3>
          </div>
          <p>The Emacspeak code base has evolved over a period of
          12 years. Except for the first six weeks of development,
          the code base has been developed and maintained using
          Emacspeak itself. This section summarizes some of the
          lessons learned with respect to <a id="idx-CHP-31-2784"
          class="indexterm" name="idx-CHP-31-2784"></a>managing
          code complexity over time. <a id="idx-CHP-31-2785" class=
          "indexterm" name="idx-CHP-31-2785"></a></p>
          <p>Throughout its existence, Emacspeak has <span class=
          "emphasis"><em>always</em></span> remained a spare-time
          project. Looking at the code base across time, I believe
          this has had a significant impact on how it has evolved.
          When working on large, complex software systems as a
          full-time project, one has the luxury of focusing one's
          entire concentration on the code base for reasonable
          stretches of time—e.g., 6 to 12 weeks. This results in
          tightly implemented code that creates <span class=
          "emphasis"><em>deep</em></span> code bases.</p>
          <p>Despite one's best intentions, this can also result in
          code that becomes hard to understand with the passage of
          time. Large software systems where a single engineer
          focuses exclusively on the project for a number of years
          are almost nonexistent; that form of single-minded focus
          usually leads to rapid burnout!</p>
          <p>In contrast, <a id="idx-CHP-31-2786" class="indexterm"
          name="idx-CHP-31-2786"></a>Emacspeak is an example of a
          large software system that has had a single engineer
          focused on it over a period of 12 years, but only in his
          spare time. A consequence of developing the system
          single-handedly over a number of years is that the code
          base has tended to be naturally "bushy." Notice the
          distribution of files and lines of code summarized in
          <a href="#summary_of_emacspeak_codebase" title=
          "Table&nbsp;31-1.&nbsp;Summary of Emacspeak codebase ">Table&nbsp;31-1,
          “Summary of Emacspeak codebase ”</a>.</p>
          <div class="table">
            <a id="summary_of_emacspeak_codebase" name=
            "summary_of_emacspeak_codebase"></a>
            <p class="title"><b>Table&nbsp;31-1.&nbsp;Summary of
            Emacspeak codebase</b></p>
            <table summary="Summary of Emacspeak codebase" border=
            "0" class="c8">
              <colgroup>
                <col />
                <col />
                <col />
                <col />
              </colgroup>
              <thead>
                <tr>
                  <th class="c3">
                    <p>Layer</p>
                  </th>
                  <th class="c3">
                    <p>Files</p>
                  </th>
                  <th class="c3">
                    <p>Lines</p>
                  </th>
                  <th class="c4">
                    <p>Percentage</p>
                  </th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td class="c5">
                    <p>TTS core</p>
                  </td>
                  <td class="c5">
                    <p>6</p>
                  </td>
                  <td class="c5">
                    <p>3866</p>
                  </td>
                  <td class="c6">
                    <p>6.0</p>
                  </td>
                </tr>
                <tr>
                  <td class="c5">
                    <p>Emacspeak core</p>
                  </td>
                  <td class="c5">
                    <p>16</p>
                  </td>
                  <td class="c5">
                    <p>12174</p>
                  </td>
                  <td class="c6">
                    <p>18.9</p>
                  </td>
                </tr>
                <tr>
                  <td class="c5">
                    <p>Emacspeak extensions</p>
                  </td>
                  <td class="c5">
                    <p>160</p>
                  </td>
                  <td class="c5">
                    <p>48339</p>
                  </td>
                  <td class="c6">
                    <p>75.0</p>
                  </td>
                </tr>
                <tr>
                  <td class="c7">
                    <p>Total</p>
                  </td>
                  <td class="c7">
                    <p>182</p>
                  </td>
                  <td class="c7">
                    <p>64379</p>
                  </td>
                  <td>
                    <p>99.9</p>
                  </td>
                </tr>
              </tbody>
            </table>
          </div>
          <p><a href="#summary_of_emacspeak_codebase" title=
          "Table&nbsp;31-1.&nbsp;Summary of Emacspeak codebase ">Table&nbsp;31-1,
          “Summary of Emacspeak codebase ”</a> highlights the
          following points:</p>
          <div class="itemizedlist">
            <ul type="disc">
              <li>
                <p>The TTS core responsible for high-quality speech
                output is isolated in 6 out of 182 files, and makes
                up six percent of the code base.</p>
              </li>
              <li>
                <p>The Emacspeak core—which provides high-level
                speech services to Emacspeak extensions, in
                addition to speech-enabling all basic Emacs
                functionality—is isolated to 16 files, and makes up
                about 19 percent of the code base.</p>
              </li>
              <li>
                <p>The rest of the system is split across 160
                files, which can be independently improved (or
                broken) without affecting the rest of the system.
                Many modules, such as <code class=
                "literal">emacspeak-url-template</code> , are
                themselves bushy—i.e., an individual URL template
                can be modified without affecting any of the other
                URL templates.</p>
              </li>
              <li>
                <p><span class="emphasis"><em>advice</em></span>
                reduces code size. The Emacspeak code base, which
                has approximately 60,000 lines of Lisp code, is a
                fraction of the size of the underlying system being
                speech-enabled. A rough count at the end of
                December 2006 shows that Emacs 22 has over a
                million lines of Lisp code; in addition, Emacspeak
                speech-enables a large number of applications not
                bundled by default with Emacs.</p>
              </li>
            </ul>
          </div>
        </div>
        <div class="sect2" lang="en" xml:lang="en">
          <div class="titlepage">
            <h3 class="title"><a id="conclusion-id017" name=
            "conclusion-id017"></a>Conclusion</h3>
          </div>
          <p>Here is a brief summary of the <a id="idx-CHP-31-2787"
          class="indexterm" name="idx-CHP-31-2787"></a>insights
          gained from implementing and using Emacspeak:</p>
          <div class="itemizedlist">
            <ul type="disc">
              <li>
                <p>Lisp <span class=
                "emphasis"><em>advice</em></span> , and its
                object-oriented equivalent Aspect Oriented
                Programming, are very effective means for
                implementing cross-cutting concerns—e.g.,
                speech-enabling a visual interface.</p>
              </li>
              <li>
                <p><span class="emphasis"><em>advice</em></span> is
                a powerful means for discovering potential points
                of extension in a complex software system.</p>
              </li>
              <li>
                <p>Focusing on basic web architecture, and relying
                on a data-oriented web backed by standardized
                protocols and formats, leads to powerful spoken web
                access.</p>
              </li>
              <li>
                <p>Focusing on the final user experience, as
                opposed to individual interaction widgets such as
                sliders and tree controls, leads to a highly
                efficient, eyes-free environment.</p>
              </li>
              <li>
                <p>Visual interaction relies heavily on the human
                eye's ability to rapidly scan the visual display.
                Effective eyes-free interaction requires
                transferring some of this responsibility to the
                computer because listening to large amounts of
                information is time-consuming. Thus, search in
                every form is critical for delivering effective
                eyes-free interaction, on the continuum from the
                smallest scale (such as Emacs' incremental search
                to find the right item in a local document) to the
                largest (such as a Google search to quickly find
                the right document on the global Web).</p>
              </li>
              <li>
                <p>Visual complexity, which may become merely an
                irritant for users capable of using complex visual
                interfaces, is a show-stopper for eyes-free
                interaction. Conversely, tools that emerge early in
                an eyes-free environment eventually show up in the
                mainstream when the nuisance value of complex
                visual interfaces crosses a certain threshold. Two
                examples of this from the Emacspeak experience
                are:</p>
              </li>
            </ul>
          </div>
          <table class="simplelist" border="0" summary=
          "Simple list">
            <tr>
              <td>—RSS and Atom feeds replacing the need for
              screen-scraping just to retrieve essential
              information such as the titles of articles.</td>
            </tr>
            <tr>
              <td>—Emacspeak's use of XSLT to filter content in
              2000 parallels the advent of Grease-monkey for
              applying custom client-side JavaScript to web pages
              in 2005.</td>
            </tr>
          </table>
        </div>
      </div>
      <div class="sect1" lang="en" xml:lang="en">
        <div class="titlepage">
          <h2 class="title c2"><a id="acknowledgments-id006" name=
          "acknowledgments-id006"></a>31.5.&nbsp;Acknowledgments</h2>
        </div>
        <p>Emacspeak would not exist without Emacs and the
        ever-vibrant Emacs developer community that has made it
        possible to do everything from within Emacs. The Emacspeak
        implementation would not have been possible without Hans
        Chalupsky's excellent advice implementation for Emacs
        Lisp.</p>
        <p>Project <span class="emphasis"><em>libxslt</em></span>
        from the GNOME project has helped breathe fresh life into
        William Perry's Emacs W3 browser; Emacs W3 was one of the
        early HTML rendering engines, but the code has not been
        updated in over eight years. That the W3 code base is still
        usable and extensible bears testimony to the flexibility
        and power afforded by Lisp as the implementation language.
        <a id="I_indexterm31_tt718" class="indexterm" name=
        "I_indexterm31_tt718"></a></p>
      </div>
    </div>
    <div class="colophon" lang="en" xml:lang="en">
      <h2 class="title"><a id="afterword" name=
      "afterword"></a>Afterword</h2>
      <p><span class="emphasis"><em>Andy Oram</em></span></p>
      <p><span class="emphasis"><em>Beautiful code surveys the
      range of human invention and ingenuity</em></span> in one
      area of endeavor: the development of computer systems. The
      beauty in each chapter comes from the discovery of unique
      solutions, a discovery springing from the authors' power to
      look beyond set boundaries, to recognize needs overlooked by
      others, and to find surprising solutions to troubling
      problems.</p>
      <p>Many of the authors confronted limitations—in the physical
      environment, in the resources available, or in the very
      definition of their requirements—that made it hard even to
      imagine solutions. Others entered domains where solutions
      already existed, but brought in a new vision and a conviction
      that something much better could be achieved.</p>
      <p>All the authors in this book have drawn lessons from their
      projects. But we can also draw some broader lessons after
      making the long and eventful journey through the whole
      book.</p>
      <p>First, there are times when tried and true rules really do
      work. So, often one encounters difficulties when trying to
      maintain standards for robustness, readability, or other
      tenets of good software engineering. In such situations, it
      is not always necessary to abandon the principles that hold
      such promise. Sometimes, getting up and taking a walk around
      the problem can reveal a new facet that allows one to meet
      the requirements without sacrificing good technique.</p>
      <p>On the other hand, some chapters confirm the old cliché
      that one must know the rules before one can break them. Some
      of the authors built up decades of experience before taking a
      different path toward solving one thorny problem—and this
      experience gave them the confidence to break the rules in a
      constructive way.</p>
      <p>On the other hand, cross-disciplinary studies are also
      championed by the lessons in this book. Many authors came
      into new domains and had to fight their way in relative
      darkness. In these situations, a particularly pure form of
      creativity and intelligence triumphed.</p>
      <p>Finally, we learn from this book that beautiful solutions
      don't last for all time. New circumstances always require a
      new look. So, if you read the book and thought, "I can't use
      these authors' solutions on any of my own projects," don't
      worry—next time these authors have projects, they will use
      different solutions, too.</p>
      <p>For about two months I worked intensively on this book by
      helping authors hone their themes and express their points.
      This immersion in the work of superbly talented inventors
      proved to be inspiring and even uplifting. It gave me the
      impulse to try new things, and I hope this book does the same
      for its readers.</p>
    </div>
  </div>
</body>
</html>
